{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b78d07e3-5aad-4fd3-aff0-d4c264b18852",
   "metadata": {},
   "source": [
    "#### Tapex : Model (from hugging face) that understand tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e0c6d3f6-cae5-4d62-b0bf-c48434a94597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPO: https://github.com/microsoft/Table-Pretraining\n",
    "\n",
    "# Hugging Face model link: https://huggingface.co/microsoft/tapex-base-finetuned-wikisql\n",
    "\n",
    "# Paper link: https://arxiv.org/pdf/2107.07653\n",
    "\n",
    "# My Chatgpt conversation about this model (confidential): https://chatgpt.com/c/696fa4c0-03b0-8322-a886-a24f4064854c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf48980-3b01-4318-aa5c-1901122159f9",
   "metadata": {},
   "source": [
    "## Use Online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39fc5232-9f99-416e-b128-78c69cc92a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TapexTokenizer, BartForConditionalGeneration\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "757aa62d-a5e6-4f9c-924e-1f2f3f76319c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TapexTokenizer.from_pretrained(\"microsoft/tapex-base-finetuned-wikisql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab3b2c77-772e-4dc9-96a2-490e998eedbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409f53bd363d4085a22e067bc12946b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/558M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\I . J\\.cache\\huggingface\\hub\\models--microsoft--tapex-base-finetuned-wikisql. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3155aae7018b4f5caa4973e7a30f6e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfef08a289324dc5808d284cecfffded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/236 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = BartForConditionalGeneration.from_pretrained(\"microsoft/tapex-base-finetuned-wikisql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77c17f74-ffe1-4290-b6b0-ece5e249d16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"year\": [1896, 1900, 1904, 2004, 2008, 2012],\n",
    "    \"city\": [\"athens\", \"paris\", \"st. louis\", \"athens\", \"beijing\", \"london\"]\n",
    "}\n",
    "table = pd.DataFrame.from_dict(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8494eca-9aca-41bc-aa94-db13d6706f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tapex accepts uncased input since it is pre-trained on the uncased corpus\n",
    "query = \"In which year did beijing host the Olympic Games?\"\n",
    "\n",
    "encoding = tokenizer(table=table, query=query, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15c8367c-959e-4031-ad60-512a1b30d8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0,    11,    61,    76,   222,    28, 40049,  1482,     5,  1021,\n",
       "         31434,   636,   426,   116, 11311,  4832,    76,  1721,   343,  3236,\n",
       "           112,  4832, 42773,  1721,    23, 27859,  3236,   132,  4832, 23137,\n",
       "          1721,  2242,   354,  3236,   155,  4832, 42224,  1721,  1690,     4,\n",
       "         26120,   354,  3236,   204,  4832,  4482,  1721,    23, 27859,  3236,\n",
       "           195,  4832,  2266,  1721,    28, 40049,  3236,   231,  4832,  1125,\n",
       "          1721,   784, 24639,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bcd1a127-4d4b-46c5-afcf-6b718b755dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' 2008.0']\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(**encoding)\n",
    "\n",
    "print(tokenizer.batch_decode(outputs, skip_special_tokens=True))\n",
    "# [' 2008.0']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ab84bd-7411-46f4-813d-976a67261ccf",
   "metadata": {},
   "source": [
    "## Download Model in Local Machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b2848d0-4146-4a30-ac2d-7e525f262fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model locally!\n"
     ]
    }
   ],
   "source": [
    "from transformers import TapexTokenizer, BartForConditionalGeneration\n",
    "\n",
    "model_name = \"microsoft/tapex-base-finetuned-wikisql\"\n",
    "save_dir = \"./tapex_local\"\n",
    "\n",
    "tokenizer = TapexTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "model.save_pretrained(save_dir)\n",
    "\n",
    "print(\"Saved model locally!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abacfd11-6fa8-4b3d-a2cc-aba60c9b0382",
   "metadata": {},
   "source": [
    "### Load downloaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68dbf6dc-322b-4f0f-8260-e6bdb782b748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offline TAPEX ready!\n"
     ]
    }
   ],
   "source": [
    "from transformers import TapexTokenizer, BartForConditionalGeneration\n",
    "\n",
    "tokenizer = TapexTokenizer.from_pretrained(\n",
    "    \"./tapex_local\",\n",
    "    local_files_only=True\n",
    ")\n",
    "\n",
    "model = BartForConditionalGeneration.from_pretrained(\n",
    "    \"./tapex_local\",\n",
    "    local_files_only=True\n",
    ")\n",
    "\n",
    "print(\"Offline TAPEX ready!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dca4df-d2b6-4260-83fd-f7740fc82f0b",
   "metadata": {},
   "source": [
    "### Use downloaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2fc1679f-a454-4d6b-be22-fe5fa30564f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"year\": [1896, 1900, 1904, 2004, 2008, 2012],\n",
    "    \"city\": [\"athens\", \"paris\", \"st. louis\", \"athens\", \"beijing\", \"london\"]\n",
    "}\n",
    "\n",
    "table = pd.DataFrame(data)\n",
    "table = table.astype(str)\n",
    "\n",
    "question = \"In which year did beijing host the Olympic Games?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "51bba3ca-7b3e-4ae9-811f-1052f59effeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' 2008.0']\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer(table=table, query=question, return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "outputs = model.generate(**encoding)\n",
    "\n",
    "answer = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dd6164-a417-4034-a099-530dfadee43b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
